# Environment Variables Template
# Copy this file to .env and replace the placeholder values

# Hugging Face Token (required for PyAnnote speaker diarization models)
# Get token from: https://huggingface.co/settings/tokens
# Accept model licenses at:
#   - https://huggingface.co/pyannote/speaker-diarization-3.1
#   - https://huggingface.co/pyannote/segmentation-3.0
HF_TOKEN=your_huggingface_token_here

# LLM API Configuration (required for AI summarization)
# NOTE: The application automatically appends '/v1/chat/completions' to the URL
# Must use OpenAI-compatible API endpoints
# Example base URLs (do NOT include /v1/chat/completions):
#   - OpenAI: https://api.openai.com
#   - Ollama (v0.1.14+): http://localhost:11434
#   - vLLM: http://localhost:8000
#   - LM Studio: http://localhost:1234
LLM_API_URL=http://localhost:1234
LLM_MODEL_NAME=qwen2.5-14b-instruct
LLM_API_KEY=  # Optional - leave empty for local servers

# Database Configuration
# Generate secure password with: openssl rand -base64 32
POSTGRES_PASSWORD=changeme

# Timezone Configuration (optional)
# Timezone offset in hours for export timestamps
# Examples: +8 for Singapore/GMT+8, -5 for EST, 0 for UTC
TIMEZONE_OFFSET=+8

# GPU Configuration (optional)
# Control which NVIDIA GPUs are visible to the container
# Options: 'all', '0', '0,1', etc.
NVIDIA_VISIBLE_DEVICES=all

# Demo Mode (optional)
# Set to 'true' to skip backend health check (for static deployments like GitHub Pages)
VITE_DEMO_MODE=false
