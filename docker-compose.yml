services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: backend
    environment:
      - HF_TOKEN=${HF_TOKEN:-CHANGEME}
      - LLM_API_URL=${LLM_API_URL:-CHANGEME}
      - LLM_MODEL_NAME=${LLM_MODEL_NAME:-CHANGEME}
      - PYTHONUNBUFFERED=1
    volumes:
      - audiofiles:/app/audiofiles
      - logs:/app/logs
      - transcripts:/app/transcripts
      - summary:/app/summary
      - whisper_cache:/root/.cache/whisper
    ports:
      - "8000:8000"
    depends_on:
      - frontend
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - shared-network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: frontend
    ports:
      - "3000:80"
    networks:
      - shared-network

volumes:
  audiofiles:
  logs:
  transcripts:
  whisper_cache:
  summary:

networks:
  shared-network:
    name: shared-network
    external: true
    # driver: bridge
